clear;clc;

x = load('./wpbcx.dat');
x = [x ones(length(x), 1)];
y = load('./wpbcy.dat');
[num_samples, num_features] = size(x);
num_folds = 10;
w = normrnd(0, 1, [num_features 1]) * 0.001; % generate random starting W from normal random numbers

indices = crossvalind('Kfold', num_samples, num_folds);

for i = 1:num_folds
   test_idx = (indices == i);
   train_idx = ~test_idx;
   
   Xtrain = x(train_idx);
   Ytrain = y(train_idx);
   Xtest = x(test_idx);
   Ytest = y(test_idx);
   
   % Logistic regression
   [w] = LogisticRegressionTrain( w, x, y, lr, num_iterations )
   
   % Naive bayes
   [ u_true, std_true, u_false, std_false, prob_true, prob_false ] = NaiveBayesTrain( Xtrain, Ytrain);
   nb_pred_train = NaiveBayesPredict( Xtrain, u_true, std_true, u_false, std_false, prob_true, prob_false);   
   nb_pred_test = NaiveBayesPredict( Xtest, u_true, std_true, u_false, std_false, prob_true, prob_false);
   
   nb_train_acc = mean(nb_pred_train == Ytrain);
   nb_test_acc = mean(nb_pred_test == Ytest);
end